{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMnMST0LNXGtEJ0pahsdBmC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JK-the-Ko/AI-and-DL/blob/main/Day1/LSTM/%5B2%5DReal_Time_Vehicle_Trajectory_Prediction_with_YOLOv11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ultralytics YOLOv11를 활용한 Vehicle Trajectory Prediction**"
      ],
      "metadata": {
        "id": "w3BWaCRNeQdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 영상 다운로드"
      ],
      "metadata": {
        "id": "Kamd9yuYCcYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "file_id = \"1nLSUY4Oqb_aI3fkVeTPQ2MLEuooMjT6n\"\n",
        "output_file = \"video.zip\"  # Replace \"data_file.ext\" with the desired output filename and extension\n",
        "\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_file)"
      ],
      "metadata": {
        "id": "9UcWC1apAy6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 영상 재생"
      ],
      "metadata": {
        "id": "jTseexegCemD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/video.zip\""
      ],
      "metadata": {
        "id": "CCT4Buo_L9LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install ipywidgets"
      ],
      "metadata": {
        "id": "wn5zDLuoDwB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets\n",
        "from ipywidgets import Image\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "m-zrvylYJIbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_widget = ipywidgets.Video.from_file(\"/content/train_val.mp4\")\n",
        "display(video_widget)"
      ],
      "metadata": {
        "id": "f6Gf4ipPBBEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 데이터셋 생성"
      ],
      "metadata": {
        "id": "fbncTIwnDWHb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A. Ultralytics 설치"
      ],
      "metadata": {
        "id": "UihEpOihDY40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install ultralytics"
      ],
      "metadata": {
        "id": "hdPgTLKKETJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B. Hyperparameter 설정"
      ],
      "metadata": {
        "id": "W-3uy-OoedYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = {\"video_size\": 640, \"seed\":42, \"train_val_ratio\":0.9, \"input_frame\":40, \"target_frame\":10, \"conf\":0.05, \"iou\":0.05,\n",
        "       \"in_channels\":2, \"hid_channels\":256, \"out_channels\":2, \"num_layer\":4, \"p\":0.1,\n",
        "       \"batch_size\":256, \"total_epoch\":10, \"lr\":1e-4, \"decay_rate\":1e-2}"
      ],
      "metadata": {
        "id": "FiehbFrnDqrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C. Frame 별로 영상을 나누어 데이터셋 생성"
      ],
      "metadata": {
        "id": "AfSOM5IDEPVo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### i. 라이브러리 불러오기"
      ],
      "metadata": {
        "id": "6yXDhCCGekS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import makedirs\n",
        "\n",
        "import random\n",
        "from random import shuffle\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "74XuKGGYENnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ii. 필요 함수 설정"
      ],
      "metadata": {
        "id": "3FqYazN4el8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_seed(seed) :\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "VygxnoZYFRKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object) :\n",
        "  def __init__(self) :\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self) :\n",
        "    self.val = 0\n",
        "    self.avg = 0\n",
        "    self.sum = 0\n",
        "    self.count = 0\n",
        "\n",
        "  def update(self, val, n=1) :\n",
        "    self.val = val\n",
        "    self.sum += val*n\n",
        "    self.count += n\n",
        "    self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "O0BJgSdkP5qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### iii. 영상 재생을 위한 Image 인스턴스 생성"
      ],
      "metadata": {
        "id": "uA23YEVqepTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video = Image()"
      ],
      "metadata": {
        "id": "tbg-xXPBDVIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### iv. YOLOv11을 활용한 Vehicle 좌표 추출"
      ],
      "metadata": {
        "id": "r3a70-aweser"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Pretrained YOLOv11 Model Weight\n",
        "yolo = YOLO(\"yolo11m.pt\")\n",
        "yolo.info()\n",
        "\n",
        "# Load Video\n",
        "video_path = \"/content/train_val.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Save Object Tracking Results\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "out = cv2.VideoWriter(f\"/content/tracking_results.mp4\", fourcc, cap.get(cv2.CAP_PROP_FPS), (opt[\"video_size\"], opt[\"video_size\"]))\n",
        "\n",
        "# Create Dictionary & List Instance\n",
        "track_history = defaultdict(lambda: [])\n",
        "data = []\n",
        "\n",
        "display(video)\n",
        "\n",
        "with torch.no_grad() :\n",
        "  while cap.isOpened() :\n",
        "    # Retrieve Frame\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if ret :\n",
        "      # Get Object Tracking Results\n",
        "      results = yolo.track(frame, persist=True, imgsz=opt[\"video_size\"], conf=opt[\"conf\"], iou=opt[\"iou\"], verbose=False)\n",
        "\n",
        "      # Get the Boxes and Track IDs\n",
        "      boxes = results[0].boxes.xywh.cpu()\n",
        "      track_ids = results[0].boxes.id.int().cpu().tolist()\n",
        "      cls_ids = results[0].boxes.cls.int().cpu().tolist()\n",
        "\n",
        "      # Visualize the Results on the Frame\n",
        "      annotated_frame = results[0].plot()\n",
        "      out.write(annotated_frame)\n",
        "      annotated_frame = cv2.imencode(\".jpg\", annotated_frame)[1].tobytes()\n",
        "      video.value = annotated_frame\n",
        "\n",
        "      # Plot the tracks\n",
        "      for box, track_id, cls_id in zip(boxes, track_ids, cls_ids) :\n",
        "        if cls_id == 2 or cls_id == 5 or cls_id == 7 : # Car / Truck / Bus\n",
        "          x, y, w, h = box # Bounding Box Info\n",
        "          track = track_history[track_id]\n",
        "          x, y = float(x), float(y)\n",
        "          track.append((x, y)) # (x, y) Center Point\n",
        "\n",
        "          if len(track) > (opt[\"input_frame\"] + opt[\"target_frame\"]) : # Input Frames + Target Frames\n",
        "            data.append(track) # Add Data\n",
        "            track.pop(0)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "0E9b-s8UDlvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### D. Frame을 기준으로 데이터셋 생성"
      ],
      "metadata": {
        "id": "jYqRqJs8cSja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix Seed\n",
        "fix_seed(opt[\"seed\"])\n",
        "\n",
        "# Shuffle Data\n",
        "shuffle(data)\n",
        "\n",
        "# Compute Training Dataset Size\n",
        "train_len = int(len(data)*opt[\"train_val_ratio\"])\n",
        "\n",
        "# Split Training & Validation Dataset\n",
        "train_df, val_df = pd.DataFrame(data=data[:train_len]), pd.DataFrame(data=data[train_len:])\n",
        "\n",
        "# Replace Column Names\n",
        "col_name = {}\n",
        "for i in range(opt[\"input_frame\"] + opt[\"target_frame\"]) :\n",
        "  col_name[i] = f\"frame_{i}\"\n",
        "\n",
        "# Create Directory\n",
        "save_dir = \"/content/csv\"\n",
        "makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Save Training & Validation Dataset\n",
        "train_df, val_df = train_df.rename(columns=col_name), val_df.rename(columns=col_name)\n",
        "train_df.to_csv(f\"{save_dir}/train_dataset.csv\", index=False), val_df.to_csv(f\"{save_dir}/val_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "1yFMySgnPNki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### E. 데이터셋 살펴보기"
      ],
      "metadata": {
        "id": "rQrNgo-IcW-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head(10)"
      ],
      "metadata": {
        "id": "akVTRHIyIP7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Custom Dataloader 생성"
      ],
      "metadata": {
        "id": "IpBX0r5qPVYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "6WcgpT_KPOEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LoadDataset(Dataset) :\n",
        "  def __init__(self, opt, for_val) :\n",
        "    # Inheritance\n",
        "    super(LoadDataset, self).__init__()\n",
        "\n",
        "    # Initialize Variable\n",
        "    self.opt = opt\n",
        "\n",
        "    # Load CSV\n",
        "    self.data = self.load_csv(\"/content/csv/val_dataset.csv\" if for_val else \"/content/csv/train_dataset.csv\")\n",
        "\n",
        "  def load_csv(self, csv_dir) :\n",
        "    # Convert into Pillow Image\n",
        "    data = pd.read_csv(csv_dir)\n",
        "\n",
        "    return data\n",
        "\n",
        "  def __getitem__(self, index) :\n",
        "    # Split Sequence\n",
        "    input, target = self.data.iloc[index][:self.opt[\"input_frame\"]], self.data.iloc[index][self.opt[\"input_frame\"]:]\n",
        "\n",
        "    # Convert to PyTorch Tensor\n",
        "    input_x, input_y = [literal_eval(i)[0] for i in input], [literal_eval(i)[1] for i in input]\n",
        "    input_x, input_y = torch.tensor(input_x).unsqueeze(-1), torch.tensor(input_y).unsqueeze(-1)\n",
        "\n",
        "    target_x, target_y = [literal_eval(i)[0] for i in target], [literal_eval(i)[1] for i in target]\n",
        "    target_x, target_y = torch.tensor(target_x).unsqueeze(-1), torch.tensor(target_y).unsqueeze(-1)\n",
        "\n",
        "    # Apply Min-Max Normalization\n",
        "    input_x, input_y = self.min_max_norm(input_x, 0, self.opt[\"video_size\"]), self.min_max_norm(input_y, 0, self.opt[\"video_size\"])\n",
        "    target_x, target_y = self.min_max_norm(target_x, 0, self.opt[\"video_size\"]), self.min_max_norm(target_y, 0, self.opt[\"video_size\"])\n",
        "\n",
        "    # Concatenate Tensor ([#Seq, 2])\n",
        "    input = torch.cat([input_x, input_y], dim=-1)\n",
        "    target = torch.cat([target_x, target_y], dim=-1)\n",
        "\n",
        "    return input, target\n",
        "\n",
        "  def __len__(self) :\n",
        "    # Get Number of Data\n",
        "    return self.data.shape[0]\n",
        "\n",
        "  def min_max_norm(self, input, min, max) :\n",
        "    output = (input-min)/(max-min)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "7-rWZxhxPXxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. LSTM Model"
      ],
      "metadata": {
        "id": "2vwvyDNrPukt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A. Trajectory 예측을 위한 모델 생성"
      ],
      "metadata": {
        "id": "FzOiWT-6fBWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "HHwXDqeSPv7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module) :\n",
        "  def __init__(self, opt) :\n",
        "    # Inheritance\n",
        "    super(LSTM, self).__init__()\n",
        "\n",
        "    # Initialize Variable\n",
        "    self.opt = opt\n",
        "\n",
        "    # Create LSTM Layer Instance\n",
        "    self.lstm = nn.LSTM(opt[\"hid_channels\"], opt[\"hid_channels\"], num_layers=opt[\"num_layer\"], bidirectional=False, batch_first=True, dropout=opt[\"p\"] if opt[\"num_layer\"] != 1 else 0)\n",
        "    self.bilstm = nn.LSTM(opt[\"hid_channels\"], opt[\"hid_channels\"]//2, num_layers=opt[\"num_layer\"], bidirectional=True, batch_first=True, dropout=opt[\"p\"] if opt[\"num_layer\"] != 1 else 0)\n",
        "\n",
        "    # Create FC Layer Instance\n",
        "    self.input2lstm = nn.Linear(opt[\"in_channels\"], opt[\"hid_channels\"])\n",
        "    self.input2bilstm = nn.Linear(opt[\"in_channels\"], opt[\"hid_channels\"])\n",
        "    self.input2output = nn.Linear(opt[\"in_channels\"], opt[\"hid_channels\"])\n",
        "    self.fc0 = nn.Linear(opt[\"hid_channels\"]*2, opt[\"hid_channels\"], bias=False)\n",
        "    self.fc1 = nn.Linear(opt[\"hid_channels\"], opt[\"hid_channels\"], bias=False)\n",
        "    self.fc2 = nn.Linear(opt[\"hid_channels\"], opt[\"out_channels\"])\n",
        "\n",
        "    # Create Layer Normalization Layer Instance\n",
        "    self.norm0 = nn.LayerNorm(opt[\"hid_channels\"])\n",
        "    self.norm1 = nn.LayerNorm(opt[\"hid_channels\"])\n",
        "\n",
        "    # Create Activation Layer Instance\n",
        "    self.act = nn.ReLU(inplace=True)\n",
        "\n",
        "  def forward(self, input) :\n",
        "    lstm_input, bilstm_input = self.input2lstm(input), self.input2bilstm(input)\n",
        "\n",
        "    lstm_h0 = torch.zeros(self.opt[\"num_layer\"], lstm_input.size(0), self.opt[\"hid_channels\"]).to(input.device)\n",
        "    lstm_c0 = torch.zeros(self.opt[\"num_layer\"], lstm_input.size(0), self.opt[\"hid_channels\"]).to(input.device)\n",
        "\n",
        "    bilstm_h0 = torch.zeros(self.opt[\"num_layer\"]*2, bilstm_input.size(0), self.opt[\"hid_channels\"]//2).to(input.device)\n",
        "    bilstm_c0 = torch.zeros(self.opt[\"num_layer\"]*2, bilstm_input.size(0), self.opt[\"hid_channels\"]//2).to(input.device)\n",
        "\n",
        "    lstm_output, _ = self.lstm(lstm_input, (lstm_h0, lstm_c0))\n",
        "    bilstm_output, _ = self.bilstm(bilstm_input, (bilstm_h0, bilstm_c0))\n",
        "\n",
        "    output = self.norm0(self.act(self.fc0(torch.cat([lstm_output, bilstm_output], dim=-1))))\n",
        "    output = self.norm1(self.act(self.fc1(output))) + self.input2output(input)\n",
        "    output = self.fc2(output)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "rTZ7v1_aPvTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Trajectory 예측 모델 훈련 진행"
      ],
      "metadata": {
        "id": "XsE9DPdNQAT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "OtST8bVWQArH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fix_seed(opt[\"seed\"])\n",
        "\n",
        "# Load Training Dataset\n",
        "train_dataset = LoadDataset(opt, for_val=False)\n",
        "train_loader = DataLoader(train_dataset, batch_size=opt[\"batch_size\"], drop_last=True, shuffle=True)\n",
        "\n",
        "# Load Validation Dataset\n",
        "val_dataset = LoadDataset(opt, for_val=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=opt[\"batch_size\"], drop_last=False, shuffle=False)\n",
        "\n",
        "# Fix Seed\n",
        "fix_seed(opt[\"seed\"])\n",
        "\n",
        "# Create Model Instance\n",
        "model = LSTM(opt)\n",
        "\n",
        "# Compute Number of Parameters\n",
        "num_parameter = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"# Parameters : {num_parameter:,}\")\n",
        "\n",
        "# Create Optimizer Instance\n",
        "optimizer = optim.Adam(model.parameters(), lr=opt[\"lr\"])\n",
        "\n",
        "# Create Scheduler Instance\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
        "                                                 T_max=opt[\"total_epoch\"]*len(train_loader),\n",
        "                                                 eta_min=opt[\"lr\"]*opt[\"decay_rate\"])\n",
        "\n",
        "# Create Loss Function Instance\n",
        "criterion = nn.L1Loss()\n",
        "\n",
        "# Determine Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device Type : {device}\")\n",
        "\n",
        "# Assign Device\n",
        "model = model.to(device)\n",
        "\n",
        "# Create Average Meter Instance\n",
        "train_loss, val_loss = AverageMeter(), AverageMeter()\n",
        "\n",
        "# Create List Instance\n",
        "train_loss_list, val_loss_list = [], []\n",
        "\n",
        "# Create Directory\n",
        "ckpt_dir, graph_dir = \"ckpt/lstm\", \"result/lstm\"\n",
        "makedirs(ckpt_dir, exist_ok=True), makedirs(graph_dir, exist_ok=True)\n",
        "\n",
        "# Set Best loss\n",
        "best_loss = np.inf\n",
        "\n",
        "# Start Training\n",
        "for epoch in range(1, opt[\"total_epoch\"]+1) :\n",
        "  # Create TQDM Dataloader Instance\n",
        "  train_bar = tqdm(train_loader)\n",
        "\n",
        "  # Reset Average Meter Instance\n",
        "  train_loss.reset()\n",
        "\n",
        "  # Set Training Mode\n",
        "  model.train()\n",
        "\n",
        "  # Training Phase\n",
        "  for data in train_bar :\n",
        "    # Load Dataset\n",
        "    input, target = data\n",
        "\n",
        "    # Assign Device\n",
        "    input, target = input.to(device), target.to(device)\n",
        "\n",
        "    # Set Gradient to 0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Get Prediction\n",
        "    pred = model(input)\n",
        "\n",
        "    # Compute Loss\n",
        "    loss = criterion(pred[:,-opt[\"target_frame\"]:,:], target)\n",
        "\n",
        "    # Back-Propagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Update Weight\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update Learning Rate Scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    # Compute Averaged Loss\n",
        "    train_loss.update(loss.detach().cpu().item(), opt[\"batch_size\"])\n",
        "\n",
        "    # Update Progess Bar Status\n",
        "    train_bar.set_description(desc=f\"[{epoch}/{opt['total_epoch']}] [Train] < Loss:{train_loss.avg:.4f} >\")\n",
        "\n",
        "  # Add Training Loss\n",
        "  train_loss_list.append(train_loss.avg)\n",
        "\n",
        "  # Create TQDM Dataloader Instance\n",
        "  val_bar = tqdm(val_loader)\n",
        "\n",
        "  # Reset Average Meter Instance\n",
        "  val_loss.reset()\n",
        "\n",
        "  # Set Validation Mode\n",
        "  model.eval()\n",
        "\n",
        "  # Validation Phase\n",
        "  for data in val_bar :\n",
        "    # Load Dataset\n",
        "    input, target = data\n",
        "\n",
        "    # Assign Device\n",
        "    input, target = input.to(device), target.to(device)\n",
        "\n",
        "    with torch.no_grad() :\n",
        "      # Get Prediction\n",
        "      pred = model(input)\n",
        "\n",
        "    # Compute Loss\n",
        "    loss = criterion(pred[:,-opt[\"target_frame\"]:,:], target)\n",
        "\n",
        "    # Compute Averaged Loss\n",
        "    val_loss.update(loss.detach().cpu().item(), opt[\"batch_size\"])\n",
        "\n",
        "    # Update Progess Bar Status\n",
        "    val_bar.set_description(desc=f\"[{epoch}/{opt['total_epoch']}] [Val] < Loss:{val_loss.avg:.4f} >\")\n",
        "\n",
        "  # Add Validation Loss\n",
        "  val_loss_list.append(val_loss.avg)\n",
        "\n",
        "  # Save Network\n",
        "  if val_loss.avg < best_loss :\n",
        "    best_loss = val_loss.avg\n",
        "    torch.save(model.state_dict(), f\"{ckpt_dir}/best.pth\")\n",
        "  torch.save(model.state_dict(), f\"{ckpt_dir}/latest.pth\")\n",
        "\n",
        "  # Plot Training vs. Validation Loss Graph\n",
        "  plt.clf()\n",
        "  plt.plot(np.arange(epoch), train_loss_list, label=\"Training Loss\")\n",
        "  plt.plot(np.arange(epoch), val_loss_list, label=\"Validation Loss\")\n",
        "  plt.title(\"Loss (Training vs. Validation)\")\n",
        "  plt.xlabel(\"Epoch\"), plt.ylabel(\"Loss\")\n",
        "  plt.legend(loc=\"best\")\n",
        "  plt.savefig(f\"{graph_dir}/loss.png\")"
      ],
      "metadata": {
        "id": "Y-q_aDjsQCLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Valid 데이터셋을 활용하여 Inference 진행"
      ],
      "metadata": {
        "id": "iGu2Cl5TL1AB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A. Pretrained Model 다운로드 (Best Model @ Epoch-50)"
      ],
      "metadata": {
        "id": "-hblp5Lpa5hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = \"1ij2rk2C4XQvj1Nj2GyoYkD3foDVeqwuE\"\n",
        "output_file = \"best_epoch_50.pth\"  # Replace \"data_file.ext\" with the desired output filename and extension\n",
        "\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_file)"
      ],
      "metadata": {
        "id": "nvRH653Ma8Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt[\"batch_size\"] = 8"
      ],
      "metadata": {
        "id": "Pr4yKfVrRbbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix Seed\n",
        "fix_seed(opt[\"seed\"])\n",
        "\n",
        "# Load Validation Dataset\n",
        "val_dataset = LoadDataset(opt, for_val=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=opt[\"batch_size\"], drop_last=False, shuffle=False)\n",
        "\n",
        "# Fix Seed\n",
        "fix_seed(opt[\"seed\"])\n",
        "\n",
        "# Create Model Instance\n",
        "model = LSTM(opt)\n",
        "\n",
        "# Load Pretraind Weight\n",
        "model.load_state_dict(torch.load(f\"/content/best_epoch_50.pth\"), strict=True)\n",
        "\n",
        "# Determine Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device Type : {device}\")\n",
        "\n",
        "# Assign Device\n",
        "model = model.to(device)\n",
        "\n",
        "# Create Directory\n",
        "graph_dir = \"result/val\"\n",
        "makedirs(graph_dir, exist_ok=True)\n",
        "\n",
        "# Start Test Phase\n",
        "val_bar = tqdm(val_loader)\n",
        "\n",
        "# Start Test Phase\n",
        "for index, data in enumerate(val_bar) :\n",
        "  # Load Dataset\n",
        "  input, target = data\n",
        "\n",
        "  # Assign Device\n",
        "  input, target = input.to(device), target.to(device)\n",
        "\n",
        "  with torch.no_grad() :\n",
        "    # Get Prediction\n",
        "    pred = model(input)\n",
        "\n",
        "    # Affine Transformation\n",
        "    input = (input.detach().cpu().numpy()*639).astype(\"int32\")\n",
        "\n",
        "    # Affine Transformation\n",
        "    pred = (pred[:,-opt[\"target_frame\"]:,:].clamp(0,1).detach().cpu().numpy()*639).astype(\"int32\")\n",
        "\n",
        "    # Affine Transformation\n",
        "    target = (target.detach().cpu().numpy()*639).astype(\"int32\")\n",
        "\n",
        "    # Update Progess Bar Status\n",
        "    val_bar.set_description(desc=f\"[Test] < Updating Results >\")\n",
        "\n",
        "  # Result Visualization\n",
        "  for i in range(pred.shape[0]) :\n",
        "    plt.clf()\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(list(input[i,:,0])+list(pred[i,:,0]), list(input[i,:,1])+list(pred[i,:,1]), \"r\", label=\"Prediction\")\n",
        "    plt.plot(list(input[i,:,0])+list(target[i,:,0]), list(input[i,:,1])+list(target[i,:,1]), \"g\", label=\"Ground-Truth\")\n",
        "    plt.xlabel(\"Local X Coordinate\")\n",
        "    plt.ylabel(\"Local Y Coordinate\")\n",
        "    plt.title(\"Trajectory Tracking Prediction\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.savefig(f\"{graph_dir}/trajectory_index_{index}_batch_{i}.png\")\n",
        "    plt.close()\n",
        "\n",
        "  if index >= 10 :\n",
        "    break"
      ],
      "metadata": {
        "id": "Dc_-z_NxL0cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B. Trajectory Prediction 결과 시각화 (그래프)"
      ],
      "metadata": {
        "id": "eIncz5bZT_35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_graph = cv2.imread(\"/content/result/val/trajectory_index_0_batch_0.png\")\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.box(False)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(result_graph)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "du-rLBZkS-IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Test 데이터셋을 활용하여 추론 및 결과 시각화"
      ],
      "metadata": {
        "id": "mE9YTHFvRA-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video = Image()"
      ],
      "metadata": {
        "id": "uK95wYN8YvE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Pretrained YOLOv11 Model Weight\n",
        "yolo = YOLO(\"yolo11m.pt\")\n",
        "yolo.info()\n",
        "\n",
        "# Load Video\n",
        "video_path = \"/content/test.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Create Directory for Saving Results\n",
        "save_dir = \"result/lstm\"\n",
        "makedirs(save_dir, exist_ok=True)\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "out = cv2.VideoWriter(f\"{save_dir}/tracking_prediction.mp4\", fourcc, cap.get(cv2.CAP_PROP_FPS), (opt[\"video_size\"], opt[\"video_size\"]))\n",
        "\n",
        "# Create LSTM Model Instance\n",
        "lstm = LSTM(opt).eval()\n",
        "\n",
        "# Load Pretrained LSTM Model Weight\n",
        "weights = torch.load(\"/content/best_epoch_50.pth\")\n",
        "lstm.load_state_dict(weights, strict=True)\n",
        "\n",
        "# Determine Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device Type : {device}\")\n",
        "\n",
        "# Assign Device\n",
        "lstm = lstm.to(device)\n",
        "\n",
        "# Create Dictionary Instance\n",
        "track_history = defaultdict(lambda: [])\n",
        "lstm_track_history = defaultdict(lambda: [])\n",
        "\n",
        "display(video)\n",
        "\n",
        "with torch.no_grad() :\n",
        "  while cap.isOpened() :\n",
        "    # Retrieve Frame\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if ret :\n",
        "      # Get Object Tracking Results\n",
        "      results = yolo.track(frame, persist=True, imgsz=opt[\"video_size\"], conf=opt[\"conf\"], iou=opt[\"iou\"], verbose=False)\n",
        "\n",
        "      # Get the Boxes and Track IDs\n",
        "      boxes = results[0].boxes.xywh.cpu()\n",
        "      track_ids = results[0].boxes.id.int().cpu().tolist()\n",
        "      cls_ids = results[0].boxes.cls.int().cpu().tolist()\n",
        "\n",
        "      # Visualize the Results on the Frame\n",
        "      annotated_frame = results[0].plot()\n",
        "\n",
        "      # Plot the tracks\n",
        "      for box, track_id, cls_id in zip(boxes, track_ids, cls_ids) :\n",
        "        if cls_id == 2 or cls_id == 5 or cls_id == 7 : # Car / Truck / Bus\n",
        "          x, y, w, h = box # Bounding Box Info\n",
        "          track = track_history[track_id]\n",
        "          lstm_track = lstm_track_history[track_id]\n",
        "          track.append((float(x), float(y))) # (x, y) Center Point\n",
        "          if len(track) > opt[\"input_frame\"] :\n",
        "            track.pop(0)\n",
        "            input = np.hstack(track).astype(np.int32).reshape((1, -1, 2)) # Get Input Data\n",
        "            input = torch.tensor(input).to(device)/639 # Min-Max Norm Input Data\n",
        "            pred = lstm(input)[:,-opt[\"target_frame\"]:,:].clamp(0,1).cpu().detach().numpy().reshape(-1, 2)*639 # Inference & Affine Prediction\n",
        "            for i in range(pred.shape[0]) :\n",
        "                lstm_track.append((float(pred[i][0]), float(pred[i][1]))) # Add Predictions\n",
        "\n",
        "          # Draw the Tracking Lines\n",
        "          points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
        "          cv2.polylines(annotated_frame, [points], isClosed=False, color=(0, 0, 255), thickness=2)\n",
        "\n",
        "          # Draw the Predicted Tracking Lines\n",
        "          if len(lstm_track) == opt[\"target_frame\"] :\n",
        "            pred_points = np.hstack(lstm_track).astype(np.int32).reshape((-1, 1, 2))\n",
        "            cv2.polylines(annotated_frame, [pred_points], isClosed=False, color=(255, 0, 0), thickness=2)\n",
        "          lstm_track_history[track_id] = []\n",
        "\n",
        "      # Show Object Tracking Results\n",
        "      out.write(annotated_frame)\n",
        "      annotated_frame = cv2.imencode(\".jpg\", annotated_frame)[1].tobytes()\n",
        "      video.value = annotated_frame\n",
        "\n",
        "    else:\n",
        "        break\n",
        "\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "eH6UOS48RDjA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}